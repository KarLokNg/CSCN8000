{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(246991, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284800</th>\n",
       "      <td>172784.0</td>\n",
       "      <td>2.039560</td>\n",
       "      <td>-0.175233</td>\n",
       "      <td>-1.196825</td>\n",
       "      <td>0.234580</td>\n",
       "      <td>-0.008713</td>\n",
       "      <td>-0.726571</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>-0.118228</td>\n",
       "      <td>0.435402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268048</td>\n",
       "      <td>-0.717211</td>\n",
       "      <td>0.297930</td>\n",
       "      <td>-0.359769</td>\n",
       "      <td>-0.315610</td>\n",
       "      <td>0.201114</td>\n",
       "      <td>-0.080826</td>\n",
       "      <td>-0.075071</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284801</th>\n",
       "      <td>172785.0</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.931005</td>\n",
       "      <td>-0.546012</td>\n",
       "      <td>-0.745097</td>\n",
       "      <td>1.130314</td>\n",
       "      <td>-0.235973</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314205</td>\n",
       "      <td>-0.808520</td>\n",
       "      <td>0.050343</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>-0.435870</td>\n",
       "      <td>0.124079</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.068803</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246991 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6   \n",
       "0            0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  \\\n",
       "1            0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "3            1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4            2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "5            2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284800  172784.0  2.039560 -0.175233 -1.196825  0.234580 -0.008713 -0.726571   \n",
       "284801  172785.0  0.120316  0.931005 -0.546012 -0.745097  1.130314 -0.235973   \n",
       "284803  172787.0 -0.732789 -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804  172788.0  1.919565 -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284806  172792.0 -0.533413 -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23   \n",
       "0       0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  \\\n",
       "1      -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "3       0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4       0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "5       0.476201  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "284800  0.017050 -0.118228  0.435402  ... -0.268048 -0.717211  0.297930   \n",
       "284801  0.812722  0.115093 -0.204064  ... -0.314205 -0.808520  0.050343   \n",
       "284803  0.024330  0.294869  0.584800  ...  0.214205  0.924384  0.012463   \n",
       "284804 -0.296827  0.708417  0.432454  ...  0.232045  0.578229 -0.037501   \n",
       "284806  1.577006 -0.414650  0.486180  ...  0.261057  0.643078  0.376777   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "0       0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1      -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "3      -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4       0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "5      -0.371427 -0.232794  0.105915  0.253844  0.081080    3.67      0  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "284800 -0.359769 -0.315610  0.201114 -0.080826 -0.075071    2.68      0  \n",
       "284801  0.102800 -0.435870  0.124079  0.217940  0.068803    2.69      0  \n",
       "284803 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79      0  \n",
       "284804  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88      0  \n",
       "284806  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00      0  \n",
       "\n",
       "[246991 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing the data\n",
    "filepath = '/Users/karlokng/Downloads/data/creditcard.csv'\n",
    "data = pd.read_csv(filepath)\n",
    "# 'Time' is time elapsed from first transaction of dataset\n",
    "# V1-V28 are the PCA components\n",
    "# Amount is the transaction amount\n",
    "# Positive class (i.e. 1) is fraud, negative class (i.e. 0) is not fraud.\n",
    "# we wish to detect and handle outliers for all the numerical features in the data set.\n",
    "# I will use z-score for outlier detection. \n",
    "\n",
    "# code from lab 2. \n",
    "def z_score_filter(data_col, threshold= 3):\n",
    "    \"\"\"\n",
    "    Description: A z_score filter that assigns each element \\\n",
    "        True if outlier, False otherwise\n",
    "    Input: A Series of numerical data (int or floats), \\\n",
    "        optionally a custom threshold\n",
    "    Output: A Series of boolean values\n",
    "    \"\"\"\n",
    "    data_mean = data_col.mean()\n",
    "    data_sd = data_col.std()\n",
    "\n",
    "    # Now I calculate the z_score\n",
    "    z_score = (data_col - data_mean)/data_sd\n",
    "\n",
    "    return pd.Series([(element < -threshold or element > threshold) \\\n",
    "                      for element in z_score], index= data_col.index)\n",
    "\n",
    "# iterate function over all columns\n",
    "for col in data.columns[:-1]: # iterate over all columns except for class\n",
    "    data[col + '_z_score'] = z_score_filter(data[col])\n",
    "\n",
    "# getting the columns to filter on\n",
    "filter_columns = [col for col in data if col.endswith('_z_score')]\n",
    "\n",
    "for col in filter_columns:\n",
    "    # get the indices of the outliers in this column\n",
    "    idx = data[data[col]].index\n",
    "    # drop the outliers\n",
    "    data.drop(idx, axis= 0, inplace= True)\n",
    "\n",
    "# checking if all the outliers are taken care of\n",
    "print(data[filter_columns].sum().sum())\n",
    "\n",
    "# dropping the indicator columns I just made now that I'm done with them\n",
    "data.drop(filter_columns, axis= 1, inplace= True)\n",
    "\n",
    "# check resulting dataframe to see how much data is left\n",
    "print(data.shape)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172792.0\n",
      "8.32705466544255\n",
      "9.89849927657432\n",
      "8.63638287943787\n",
      "8.489687925581698\n",
      "8.25556928744708\n",
      "7.92598967347155\n",
      "7.37778347510833\n",
      "7.1540905227738705\n",
      "6.588006067890181\n",
      "6.51131993807866\n",
      "6.09815154140999\n",
      "5.78384195040972\n",
      "5.96814731722727\n",
      "5.74761647051025\n",
      "5.49060309430583\n",
      "5.22934837153033\n",
      "4.748727436870849\n",
      "5.02862248982756\n",
      "4.88355107434502\n",
      "4.60622082428627\n",
      "4.38363756015058\n",
      "4.350406562488571\n",
      "3.7283169492430597\n",
      "3.2042803494743897\n",
      "3.12743443617826\n",
      "2.88689983689746\n",
      "2.42110184807048\n",
      "1.977978625638149\n",
      "838.07\n"
     ]
    }
   ],
   "source": [
    "# checking ranges in the columns to see if I should normalize\n",
    "for col in data.columns[:-1]:\n",
    "    print(data[col].max() - data[col].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the PCA components all have relatively similar range, but Time and Amount (which aren't PCA components) have much larger ranges. As such, I think we should normalize those two columns specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# since Time is ordinal, it would make sense for us to use min-max scaling\n",
    "# to preserve the ordinal information\n",
    "data['Time'] = (data['Time'] - data['Time'].min())/ \\\n",
    "    (data['Time'].max() - data['Time'].min())\n",
    "\n",
    "# checking distribution of the ['Amount'] column\n",
    "data['Amount'].hist()\n",
    "\n",
    "# we see that the amount is heavily right skewed\n",
    "# as such, min-max scaling may not work well\n",
    "# we could try robust scaling\n",
    "data['Amount'] = (data['Amount'] - data['Amount'].quantile(0.5))/ \\\n",
    "    (data['Amount'].quantile(0.25) - data['Amount'].quantile(0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "12.969204580625194\n"
     ]
    }
   ],
   "source": [
    "# the ranges are much more reasonably close now. \n",
    "print(data['Time'].max() - data['Time'].min())\n",
    "print(data['Amount'].max() - data['Amount'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Analytics ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246943, 31)\n",
      "(48, 31)\n"
     ]
    }
   ],
   "source": [
    "print(data[data['Class'] == 0].shape)\n",
    "print(data[data['Class'] == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data set had 492 cases of fraud. It seems that in removing the outliers, we have kind of decimated the positive class. Intuitively it kind of makes sense, as \"outlier\" transactions would probably be a higher chance to be fraud. \n",
    "\n",
    "I will re-run the outlier detection, but stratified between fraud and non-fraud cases. This way, we may remove outliers between the two cases more appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before outlier removal: \n",
      "(284315, 31)\n",
      "(492, 31)\n",
      "\n",
      "After outlier removal: \n",
      "(244155, 31)\n",
      "(442, 31)\n"
     ]
    }
   ],
   "source": [
    "# re-running outlier detection with a higher threshold\n",
    "data = pd.read_csv(filepath)\n",
    "\n",
    "print(\"Before outlier removal: \")\n",
    "print(data[data['Class'] == 0].shape)\n",
    "print(data[data['Class'] == 1].shape)\n",
    "# splitting to 2 subsets\n",
    "data_neg = data[data['Class'] == 0].copy()\n",
    "data_pos = data[data['Class'] == 1].copy()\n",
    "\n",
    "# running the z_score_filter\n",
    "for col in data.columns[:-1]:\n",
    "    data_neg[col + '_z_score'] = z_score_filter(data_neg[col], threshold= 3)\n",
    "    data_pos[col + '_z_score'] = z_score_filter(data_pos[col], threshold= 3)\n",
    "\n",
    "# combining them back\n",
    "data = pd.concat([data_neg, data_pos]).sort_index()\n",
    "\n",
    "# the rest of it goes the same as before\n",
    "filter_columns = [col for col in data if col.endswith('_z_score')]\n",
    "\n",
    "for col in filter_columns:\n",
    "    idx = data[data[col]].index\n",
    "    data.drop(idx, axis= 0, inplace= True)\n",
    "\n",
    "# re-running normalization\n",
    "data['Time'] = (data['Time'] - data['Time'].min())/ \\\n",
    "    (data['Time'].max() - data['Time'].min())\n",
    "data['Amount'] = (data['Amount'] - data['Amount'].quantile(0.5))/ \\\n",
    "    (data['Amount'].quantile(0.25) - data['Amount'].quantile(0.75))\n",
    "\n",
    "data.drop(filter_columns, axis= 1, inplace= True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"After outlier removal: \")\n",
    "print(data[data['Class'] == 0].shape)\n",
    "print(data[data['Class'] == 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this more nuanced way to check for outliers, we've preserved many more observations of fraud than before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V10        0.000000e+00\n",
       "V16        0.000000e+00\n",
       "V21        0.000000e+00\n",
       "V14        0.000000e+00\n",
       "V12        0.000000e+00\n",
       "V11        0.000000e+00\n",
       "V17        0.000000e+00\n",
       "V8         0.000000e+00\n",
       "V9         0.000000e+00\n",
       "V5         0.000000e+00\n",
       "V4         0.000000e+00\n",
       "V3         0.000000e+00\n",
       "V2         0.000000e+00\n",
       "V1         0.000000e+00\n",
       "V7         0.000000e+00\n",
       "V18        0.000000e+00\n",
       "V6        3.588570e-168\n",
       "V27       3.292951e-115\n",
       "V19        1.203296e-97\n",
       "V20        1.416010e-94\n",
       "V28        4.838884e-29\n",
       "Time       2.500622e-10\n",
       "Amount     9.773619e-09\n",
       "V24        6.255540e-05\n",
       "V26        1.559947e-03\n",
       "V25        6.707967e-03\n",
       "V22        3.899243e-02\n",
       "V15        4.052849e-01\n",
       "V13        4.516722e-01\n",
       "V23        8.752000e-01\n",
       "Class      1.000000e+00\n",
       "Name: Class, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyzing correlation\n",
    "\n",
    "# custom correlation function to compute p-values later on\n",
    "def pearsonr_pval(x, y):\n",
    "    return pearsonr(x,y)[1]\n",
    "\n",
    "corr_coeff_df = data.corr()\n",
    "p_val_coeff_df = data.corr(method= pearsonr_pval)\n",
    "\n",
    "display(p_val_coeff_df['Class'].sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that almost every column is statistically signficantly correlated to the class to a significance level of 0.05. The only features that are not statistically significantly correlated are V23, V13 and V15. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V14      -0.370582\n",
       "V17      -0.370234\n",
       "V12      -0.300812\n",
       "V10      -0.276434\n",
       "V7       -0.238932\n",
       "V16      -0.215112\n",
       "V3       -0.202955\n",
       "V1       -0.122956\n",
       "V18      -0.113877\n",
       "V5       -0.106158\n",
       "V9       -0.105387\n",
       "V6       -0.055846\n",
       "Time     -0.012792\n",
       "Amount   -0.011595\n",
       "V24      -0.008094\n",
       "V15      -0.001683\n",
       "V13      -0.001522\n",
       "V23      -0.000318\n",
       "V22       0.004174\n",
       "V25       0.005482\n",
       "V26       0.006396\n",
       "V28       0.022613\n",
       "V20       0.041699\n",
       "V19       0.042384\n",
       "V27       0.046106\n",
       "V21       0.086859\n",
       "V8        0.093404\n",
       "V2        0.132580\n",
       "V4        0.148670\n",
       "V11       0.161852\n",
       "Class     1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(corr_coeff_df['Class'].sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the magnitude of the correlation coefficients are not very big either. V11 (the feature with the highest positive correlation coefficient) has a value of 0.16, and V14 (the feature with the highest negative correlation coefficient) has a value of -0.37. This indicates relatively weak linear correlation between these features and the class value. Non-linear correlation is not captured within this measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V14', 'V17', 'V12', 'V10', 'V7', 'V11', 'V4', 'V2', 'V8', 'V21']\n"
     ]
    }
   ],
   "source": [
    "# choose top 10\n",
    "# I'll choose the 5 highest and 5 lowest correlation value, \n",
    "# with the assumption that stronger correlation strength would be helpful in prediction\n",
    " \n",
    "# [:-1] to ignore the correlation of Class with itself\n",
    "top5 = corr_coeff_df['Class'][:-1].sort_values().nlargest(5).index\n",
    "bottom5 = corr_coeff_df['Class'][:-1].sort_values().nsmallest(5).index\n",
    "\n",
    "selected_features = list(bottom5) + list(top5)\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot their distributions against Class\n",
    "\n",
    "# first, subset the dataframe for these 10 features\n",
    "data_selected = data[selected_features + ['Class']]\n",
    "\n",
    "#for col in selected_features:\n",
    "#    data_selected.plot.bar(x= col, y= 'Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model Training and Testing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V14</th>\n",
       "      <th>V17</th>\n",
       "      <th>V12</th>\n",
       "      <th>V10</th>\n",
       "      <th>V7</th>\n",
       "      <th>V11</th>\n",
       "      <th>V4</th>\n",
       "      <th>V2</th>\n",
       "      <th>V8</th>\n",
       "      <th>V21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.353705</td>\n",
       "      <td>-0.182913</td>\n",
       "      <td>-1.039343</td>\n",
       "      <td>-0.767856</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.583304</td>\n",
       "      <td>1.251555</td>\n",
       "      <td>-0.533378</td>\n",
       "      <td>-1.193843</td>\n",
       "      <td>0.403176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.458666</td>\n",
       "      <td>-0.386195</td>\n",
       "      <td>-1.220594</td>\n",
       "      <td>-0.706189</td>\n",
       "      <td>-0.005311</td>\n",
       "      <td>0.516834</td>\n",
       "      <td>1.250553</td>\n",
       "      <td>-0.544502</td>\n",
       "      <td>-1.277705</td>\n",
       "      <td>0.337533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.444620</td>\n",
       "      <td>-0.352684</td>\n",
       "      <td>-1.037526</td>\n",
       "      <td>-0.673436</td>\n",
       "      <td>0.134119</td>\n",
       "      <td>0.637241</td>\n",
       "      <td>1.123978</td>\n",
       "      <td>-0.372569</td>\n",
       "      <td>-1.106991</td>\n",
       "      <td>0.254811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.498657</td>\n",
       "      <td>-0.378811</td>\n",
       "      <td>-1.011955</td>\n",
       "      <td>-0.769161</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>0.691216</td>\n",
       "      <td>1.230724</td>\n",
       "      <td>-0.563043</td>\n",
       "      <td>-1.109582</td>\n",
       "      <td>0.344454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.329486</td>\n",
       "      <td>-0.294862</td>\n",
       "      <td>-1.001625</td>\n",
       "      <td>-0.920978</td>\n",
       "      <td>0.056579</td>\n",
       "      <td>0.612295</td>\n",
       "      <td>1.314392</td>\n",
       "      <td>-0.486721</td>\n",
       "      <td>-1.174319</td>\n",
       "      <td>0.416366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        V14       V17       V12       V10        V7       V11        V4   \n",
       "0 -1.353705 -0.182913 -1.039343 -0.767856  0.002999  0.583304  1.251555  \\\n",
       "1 -1.458666 -0.386195 -1.220594 -0.706189 -0.005311  0.516834  1.250553   \n",
       "2 -1.444620 -0.352684 -1.037526 -0.673436  0.134119  0.637241  1.123978   \n",
       "3 -1.498657 -0.378811 -1.011955 -0.769161  0.139376  0.691216  1.230724   \n",
       "4 -1.329486 -0.294862 -1.001625 -0.920978  0.056579  0.612295  1.314392   \n",
       "\n",
       "         V2        V8       V21  \n",
       "0 -0.533378 -1.193843  0.403176  \n",
       "1 -0.544502 -1.277705  0.337533  \n",
       "2 -0.372569 -1.106991  0.254811  \n",
       "3 -0.563043 -1.109582  0.344454  \n",
       "4 -0.486721 -1.174319  0.416366  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_selected[selected_features],\n",
    "                                                    data_selected['Class'],\n",
    "                                                    test_size= 0.2)\n",
    "\n",
    "# train logistic regression model \n",
    "cv_dict_logistic = cross_validate(LogisticRegression(),\n",
    "                                  X_train, y_train, cv= 5, return_estimator= True)\n",
    "df = pd.DataFrame(columns= X_train.columns)\n",
    "for i in range(0, 5):\n",
    "    val_lst = cv_dict_logistic['estimator'][i].coef_[0]\n",
    "    df.loc[i] = val_lst\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 5-fold cross validation, the trained models seem to give V14, V4, and V8 the most weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.999898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4\n",
       "accuracy   0.999796  0.999591  0.999898  0.999796  0.999898\n",
       "precision  1.000000  1.000000  1.000000  0.923077  1.000000\n",
       "recall     0.833333  0.692308  0.923077  0.923077  0.923077\n",
       "f1         0.909091  0.818182  0.960000  0.923077  0.960000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# validate logistic regression model \n",
    "cv_dict_logistic_test = cross_validate(LogisticRegression(),\n",
    "                                       X_test, y_test, cv= 5,\n",
    "                                       scoring= ['accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "res_df = pd.DataFrame([cv_dict_logistic_test['test_accuracy'], \n",
    "                       cv_dict_logistic_test['test_precision'], \n",
    "                       cv_dict_logistic_test['test_recall'], \n",
    "                       cv_dict_logistic_test['test_f1']],\n",
    "                       index = ['accuracy', 'precision', 'recall', 'f1'],\n",
    "                       columns= range(0,5))\n",
    "\n",
    "display(res_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the very imbalanced classes, we must consider the results of a dummy model where it simply predicts the majority class. The majority class here is class 0, and thus a model that simply predicts 0 for every item in the test set would, on average, attain a result of about 99%. We attain this value by the fact that there are only 442 positive cases in our full data set, and 244155 cases of negative cases. As such, if it predicts class 0 for every observation in our test set, it would get $\\frac{442}{244155} \\approx 0.99$ in accuracy. Given this baseline, our model's $\\approx 0.99$ accuracy score is a lot less impressive than taken at face value. As such, the other measures may offer more insight into the performance of our model. \n",
    "\n",
    "Precision is defined as $\\frac{TP}{TP + FP}$. In plain language, it is the number of correctly labelled positive observations out of all the observations that were identified as the positive class. Our model scored 100% in all 5 instances of the 5-fold cross validation. This means that, of the cases identified as fraud, they were all indeed cases of fraud. \n",
    "\n",
    "Recall is defined as $\\frac{TP}{TP + FN}$. It is the number of correctly labelled positive observations out of all the positive observations within the data set. Our model seems to fluctuate quite wildly between low and high observation scores. This implies that our model's recall performance is quite dependent on the exact sample of data set we feed it. This could potentially indicate an overfitting issue. Alternatively this could indicate that we still have too few cases of fraud in our data set, as some of the partitions may contain no fraud, and thus there isn't any \"positive observations\" within this partition of the dataset. \n",
    "\n",
    "F1 score is defined as $\\frac{2TP}{2TP + FP + FN}$. It is a harmonic mean of precision and recall. It seeks to find a balance between precision and recall. Since our precision is 100% across all 5 cross validations, our f1 score fluctuates similarly to our recall. However, it flucuates less as it is \"balanced out\" by the constant precision score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953125\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the test set to make predictions\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_score = model.predict(X_test)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_score)\n",
    "print(roc_auc_score(y_test, y_score))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model outperforms a random classifier, and it seems to be quite appreciably close to the perfect classifier. \n",
    "The AUC metric also indicates that th emodel preddicts the positive classes with very high confidence. These are good signs for our logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.50065499 382.1875    ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.981092</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.980683</td>\n",
       "      <td>0.981500</td>\n",
       "      <td>0.980989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.056410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064356</td>\n",
       "      <td>0.067010</td>\n",
       "      <td>0.065327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.106280</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.120930</td>\n",
       "      <td>0.125604</td>\n",
       "      <td>0.122642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4\n",
       "accuracy   0.981092  0.999591  0.980683  0.981500  0.980989\n",
       "precision  0.056410  1.000000  0.064356  0.067010  0.065327\n",
       "recall     0.916667  0.692308  1.000000  1.000000  1.000000\n",
       "f1         0.106280  0.818182  0.120930  0.125604  0.122642"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we can add class weights to our logistic regression model. \n",
    "# the 'balanced' mode uses counts of y to adjust the sample weight\n",
    "# It is inversely proportional to class frequencies, and is given by\n",
    "#n_samples / (n_classes * np.bincount(y)).\n",
    "cv_dict_logistic_test_weighted = cross_validate(LogisticRegression(class_weight='balanced'),\n",
    "                                       X_test, y_test, cv= 5,\n",
    "                                       scoring= ['accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "res_weighted_df = pd.DataFrame([cv_dict_logistic_test_weighted['test_accuracy'], \n",
    "                       cv_dict_logistic_test_weighted['test_precision'], \n",
    "                       cv_dict_logistic_test_weighted['test_recall'], \n",
    "                       cv_dict_logistic_test_weighted['test_f1']],\n",
    "                       index = ['accuracy', 'precision', 'recall', 'f1'],\n",
    "                       columns= range(0,5))\n",
    "\n",
    "# printing out the class weight just for fun.\n",
    "print(len(y_test)/(2 * np.bincount(y_test)))\n",
    "display(res_weighted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the performance is quite different. In this case, the precision metric crumbles to nearly 0, with 1 set wildly fluctuating to 1. This could be a case where there are no positive cases in this fold, and thus everything is predicted to be the negative case and achieving a result of a 100%. \n",
    "\n",
    "The recall, in turn, mostly achieves a high value of 70% to 100%. \n",
    "\n",
    "The f1 score, being a harmonic mean of the two, is very low when precision is low. \n",
    "\n",
    "This indicates to us that our model really doesn't work very well when the class imbalance is addressed. As such, perhaps other methods may perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4\n",
       "accuracy   0.999796  0.999591  0.999796  0.999898  0.999898\n",
       "precision  1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "recall     0.833333  0.692308  0.846154  0.923077  0.923077\n",
       "f1         0.909091  0.818182  0.916667  0.960000  0.960000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4\n",
       "accuracy   0.999796  0.999591  0.999796  0.999898  0.999898\n",
       "precision  1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "recall     0.833333  0.692308  0.846154  0.923077  0.923077\n",
       "f1         0.909091  0.818182  0.916667  0.960000  0.960000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_dict_neighbour_test = cross_validate(KNeighborsClassifier(),\n",
    "                                       X_test, y_test, cv= 5,\n",
    "                                       scoring= ['accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "res_neighbour_df = pd.DataFrame([cv_dict_neighbour_test['test_accuracy'], \n",
    "                       cv_dict_neighbour_test['test_precision'], \n",
    "                       cv_dict_neighbour_test['test_recall'], \n",
    "                       cv_dict_neighbour_test['test_f1']],\n",
    "                       index = ['accuracy', 'precision', 'recall', 'f1'],\n",
    "                       columns= range(0,5))\n",
    "\n",
    "cv_dict_svm_test = cross_validate(LinearSVC(max_iter= 10000),\n",
    "                                       X_test, y_test, cv= 5,\n",
    "                                       scoring= ['accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "res_svm_df = pd.DataFrame([cv_dict_svm_test['test_accuracy'], \n",
    "                       cv_dict_svm_test['test_precision'], \n",
    "                       cv_dict_svm_test['test_recall'], \n",
    "                       cv_dict_svm_test['test_f1']],\n",
    "                       index = ['accuracy', 'precision', 'recall', 'f1'],\n",
    "                       columns= range(0,5))\n",
    "\n",
    "display(res_neighbour_df)\n",
    "display(res_svm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a similar behaviour from the KNN and SVM classifiers to our logistic regression. Namely, the Precision seems abnormally high, and the Recall seems to fluctuate between iterations, and the f1-score reflecting this variance as well. \n",
    "\n",
    "I note that, when setting class_weights= 'balanced' for the LinearSVC function, it does not converge even after increasing the max iteration to 10,000. \n",
    "\n",
    "Further testing could be done to rectify the class imbalance problem in another way (perhaps with over/under sampling), potentially giving us more stable results from our models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
